{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/pbs.7507837.pbs/ipykernel_2060235/2846834199.py:38: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  y = pd.read_csv(\"y.csv\", squeeze=True, header=None)\n"
     ]
    }
   ],
   "source": [
    "num_cores=16\n",
    "\n",
    "from tune_sklearn import TuneGridSearchCV, TuneSearchCV\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RepeatedKFold,\n",
    "    LeaveOneOut,\n",
    "    RepeatedStratifiedKFold,\n",
    ")\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from skorch import NeuralNetBinaryClassifier, NeuralNetClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from functools import partial\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Read the DataFrame and Series from the CSV files\n",
    "X = pd.read_csv(\"X.csv\")\n",
    "y = pd.read_csv(\"y.csv\", squeeze=True, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   be_alcohol_freq.0.0  be_physact_walks.0.0  be_smok_packyears.0.0  \\\n",
      "0                 6.00                 40.92                  0.000   \n",
      "1                 0.15                 30.00                  0.000   \n",
      "2                 3.50                 65.58                 30.647   \n",
      "3                 6.00                 15.00                  0.000   \n",
      "4                 0.00                 15.00                 24.500   \n",
      "\n",
      "   bio_alb.0.0  bio_alp.0.0  bio_alt.0.0  bio_ast.0.0  bio_bas.0.0  \\\n",
      "0        47.06         75.7        57.04         37.3         0.02   \n",
      "1        47.90        123.6        33.65         27.5         0.00   \n",
      "2        48.89        185.4        28.27         46.1         0.00   \n",
      "3        43.32        118.6        25.55         32.0         0.00   \n",
      "4        42.44         73.3        40.87         36.3         0.00   \n",
      "\n",
      "   bio_chol.0.0  bio_cr.0.0  ...  bp_sys_avg  bp_dia_avg  ethnicity.asian  \\\n",
      "0         4.156        63.4  ...       151.5        88.5              0.0   \n",
      "1         4.692        68.2  ...       144.0        99.0              0.0   \n",
      "2         3.874       109.6  ...       132.5        77.0              0.0   \n",
      "3         5.154        58.6  ...       104.5        64.5              0.0   \n",
      "4         5.032       101.4  ...       154.0        63.5              0.0   \n",
      "\n",
      "   ethnicity.black  ethnicity.mixed  ethnicity.other  ethnicity.white  \\\n",
      "0              0.0              0.0              0.0              1.0   \n",
      "1              0.0              0.0              0.0              1.0   \n",
      "2              0.0              0.0              0.0              1.0   \n",
      "3              0.0              0.0              0.0              1.0   \n",
      "4              0.0              0.0              0.0              1.0   \n",
      "\n",
      "   smoking.never  smoking.previous  smoking.current  \n",
      "0            1.0               0.0              0.0  \n",
      "1            1.0               0.0              0.0  \n",
      "2            0.0               1.0              0.0  \n",
      "3            1.0               0.0              0.0  \n",
      "4            0.0               1.0              0.0  \n",
      "\n",
      "[5 rows x 57 columns]\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: 0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch.callbacks import EarlyStopping\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Neural network architecture with dropout\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(\n",
    "        self, dropout_prob=0, n_neurons1=8, n_neurons2=8, weight_constraint=1.0\n",
    "    ):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, n_neurons1)\n",
    "        self.dropout1 = nn.Dropout(dropout_prob)\n",
    "        self.layer2 = nn.Linear(n_neurons1, n_neurons2)\n",
    "        self.dropout2 = nn.Dropout(dropout_prob)\n",
    "        self.layer3 = nn.Linear(n_neurons2, 1)\n",
    "        self.weight_constraint = weight_constraint\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.relu(self.layer2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.layer3(x)  # Removed torch.sigmoid from the last layer\n",
    "        return x\n",
    "\n",
    "\n",
    "X_train_resampled, y_train_resampled = X_train, y_train\n",
    "input_size = X_train_resampled.shape[1]\n",
    "X_train_resampled = torch.tensor(X_train_resampled.values, dtype=torch.float32)\n",
    "y_train_resampled = torch.tensor(y_train_resampled.values, dtype=torch.float32)\n",
    "\n",
    "def tofloat32(x):\n",
    "#    return x.astype(np.float32)\n",
    "    return torch.tensor(x, dtype=torch.float32).to(device)\n",
    "\n",
    "model = NeuralNetBinaryClassifier(\n",
    "    NeuralNet,\n",
    "    criterion=nn.BCEWithLogitsLoss,  # Changed to BCEWithLogitsLoss\n",
    "    batch_size=64,\n",
    "    max_epochs=1000,\n",
    "    verbose=False,\n",
    "    optimizer=optim.Adam,\n",
    "    optimizer__lr=0.001,\n",
    "    callbacks=[EarlyStopping(patience=5)],\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "#model.to(device)\n",
    "\n",
    "cont_vars = [\n",
    "    0,\n",
    "    1,\n",
    "    2,\n",
    "    3,\n",
    "    4,\n",
    "    5,\n",
    "    6,\n",
    "    7,\n",
    "    8,\n",
    "    9,\n",
    "    10,\n",
    "    11,\n",
    "    12,\n",
    "    13,\n",
    "    14,\n",
    "    15,\n",
    "    16,\n",
    "    17,\n",
    "    18,\n",
    "    20,\n",
    "    21,\n",
    "    22,\n",
    "    23,\n",
    "    24,\n",
    "    26,\n",
    "    27,\n",
    "    28,\n",
    "    46,\n",
    "    47,\n",
    "    48,\n",
    "\n",
    "]\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[(\"scaler\", StandardScaler(), cont_vars)], remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "smote = SMOTE(sampling_strategy=0.5, random_state=42)\n",
    "under = RandomUnderSampler(sampling_strategy=1, random_state=42)\n",
    "over = RandomOverSampler(random_state=42)\n",
    "# smoteenn = SMOTEENN(random_state=42)\n",
    "# steps = [('under', under), ('model', model)]\n",
    "\n",
    "\n",
    "# Create a list of param_grids\n",
    "param_grids = [\n",
    "    {\n",
    "        \"model__optimizer\": [\n",
    "            optim.Adam,\n",
    "            optim.Adamax,\n",
    "            optim.NAdam,\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"model__optimizer__lr\": [\n",
    "            0.00001,\n",
    "            0.000025,\n",
    "            0.00005,\n",
    "            0.0001,\n",
    "            0.0005,\n",
    "            0.001,\n",
    "            0.005,\n",
    "            0.01,\n",
    "        ],\n",
    "    },\n",
    "    #{\n",
    "    #    \"model__batch_size\": [8, 16, 32, 64, 128, 256, 512],\n",
    "    #    \"model__max_epochs\": [20, 50, 150, 200, 250, 400, 600],\n",
    "    #},\n",
    "    {\n",
    "        \"model__module__n_neurons1\": [1, 2, 4, 8, 16, 32],\n",
    "        \"model__module__n_neurons2\": [1, 2, 4, 8, 16, 32],\n",
    "    },\n",
    "    {\n",
    "        \"model__module__dropout_prob\": [0.0, 0.2, 0.4, 0.6, 0.8],\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=100, random_state=42)  # changed\n",
    "roc_auc_score_2 = make_scorer(roc_auc_score, needs_threshold=False)\n",
    "\n",
    "# Initialize the best_params dictionary\n",
    "best_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'module': <class '__main__.NeuralNet'>, 'criterion': <class 'torch.nn.modules.loss.BCEWithLogitsLoss'>, 'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.01, 'max_epochs': 1000, 'batch_size': 64, 'iterator_train': <class 'torch.utils.data.dataloader.DataLoader'>, 'iterator_valid': <class 'torch.utils.data.dataloader.DataLoader'>, 'dataset': <class 'skorch.dataset.Dataset'>, 'train_split': <skorch.dataset.ValidSplit object at 0x154a48af3250>, 'callbacks': [<skorch.callbacks.training.EarlyStopping object at 0x154b4c1977f0>], 'predict_nonlinearity': 'auto', 'warm_start': False, 'verbose': False, 'device': device(type='cpu'), '_params_to_validate': {'optimizer__lr'}, 'optimizer__lr': 0.001, 'threshold': 0.5, 'callbacks__epoch_timer': <skorch.callbacks.logging.EpochTimer object at 0x154a3be918e0>, 'callbacks__train_loss': <skorch.callbacks.scoring.PassthroughScoring object at 0x154a3be91910>, 'callbacks__train_loss__name': 'train_loss', 'callbacks__train_loss__lower_is_better': True, 'callbacks__train_loss__on_train': True, 'callbacks__valid_loss': <skorch.callbacks.scoring.PassthroughScoring object at 0x154a3be91490>, 'callbacks__valid_loss__name': 'valid_loss', 'callbacks__valid_loss__lower_is_better': True, 'callbacks__valid_loss__on_train': False, 'callbacks__valid_acc': <skorch.callbacks.scoring.EpochScoring object at 0x154a3be91610>, 'callbacks__valid_acc__scoring': 'accuracy', 'callbacks__valid_acc__lower_is_better': False, 'callbacks__valid_acc__on_train': False, 'callbacks__valid_acc__name': 'valid_acc', 'callbacks__valid_acc__target_extractor': <function to_numpy at 0x154a4b3889d0>, 'callbacks__valid_acc__use_caching': True, 'callbacks__print_log': <skorch.callbacks.logging.PrintLog object at 0x154a3be91c70>, 'callbacks__print_log__keys_ignored': None, 'callbacks__print_log__sink': <built-in function print>, 'callbacks__print_log__tablefmt': 'simple', 'callbacks__print_log__floatfmt': '.4f', 'callbacks__print_log__stralign': 'right'}\n",
      "Best: 0.544678 using {'model__optimizer': <class 'torch.optim.nadam.NAdam'>}\n",
      "0.544125 (0.023989) with: {'model__optimizer': <class 'torch.optim.adam.Adam'>}\n",
      "0.543599 (0.025665) with: {'model__optimizer': <class 'torch.optim.adamax.Adamax'>}\n",
      "0.544678 (0.024886) with: {'model__optimizer': <class 'torch.optim.nadam.NAdam'>}\n",
      "{'module': <class '__main__.NeuralNet'>, 'criterion': <class 'torch.nn.modules.loss.BCEWithLogitsLoss'>, 'optimizer': <class 'torch.optim.nadam.NAdam'>, 'lr': 0.01, 'max_epochs': 1000, 'batch_size': 64, 'iterator_train': <class 'torch.utils.data.dataloader.DataLoader'>, 'iterator_valid': <class 'torch.utils.data.dataloader.DataLoader'>, 'dataset': <class 'skorch.dataset.Dataset'>, 'train_split': <skorch.dataset.ValidSplit object at 0x154a48af3250>, 'callbacks': [<skorch.callbacks.training.EarlyStopping object at 0x154b4c1977f0>], 'predict_nonlinearity': 'auto', 'warm_start': False, 'verbose': False, 'device': device(type='cpu'), '_params_to_validate': {'optimizer__lr'}, 'optimizer__lr': 0.001, 'threshold': 0.5, 'callbacks__epoch_timer': <skorch.callbacks.logging.EpochTimer object at 0x154b4da50280>, 'callbacks__train_loss': <skorch.callbacks.scoring.PassthroughScoring object at 0x154a436f09d0>, 'callbacks__train_loss__name': 'train_loss', 'callbacks__train_loss__lower_is_better': True, 'callbacks__train_loss__on_train': True, 'callbacks__valid_loss': <skorch.callbacks.scoring.PassthroughScoring object at 0x154a4357fa60>, 'callbacks__valid_loss__name': 'valid_loss', 'callbacks__valid_loss__lower_is_better': True, 'callbacks__valid_loss__on_train': False, 'callbacks__valid_acc': <skorch.callbacks.scoring.EpochScoring object at 0x154a41f41460>, 'callbacks__valid_acc__scoring': 'accuracy', 'callbacks__valid_acc__lower_is_better': False, 'callbacks__valid_acc__on_train': False, 'callbacks__valid_acc__name': 'valid_acc', 'callbacks__valid_acc__target_extractor': <function to_numpy at 0x154a4b3889d0>, 'callbacks__valid_acc__use_caching': True, 'callbacks__print_log': <skorch.callbacks.logging.PrintLog object at 0x154a41f41880>, 'callbacks__print_log__keys_ignored': None, 'callbacks__print_log__sink': <built-in function print>, 'callbacks__print_log__tablefmt': 'simple', 'callbacks__print_log__floatfmt': '.4f', 'callbacks__print_log__stralign': 'right'}\n",
      "Best: 0.547910 using {'model__optimizer__lr': 5e-05}\n",
      "0.531924 (0.030136) with: {'model__optimizer__lr': 1e-05}\n",
      "0.546373 (0.024807) with: {'model__optimizer__lr': 2.5e-05}\n",
      "0.547910 (0.025457) with: {'model__optimizer__lr': 5e-05}\n",
      "0.546558 (0.024912) with: {'model__optimizer__lr': 0.0001}\n",
      "0.545523 (0.024506) with: {'model__optimizer__lr': 0.0005}\n",
      "0.545191 (0.024235) with: {'model__optimizer__lr': 0.001}\n",
      "0.536461 (0.022762) with: {'model__optimizer__lr': 0.005}\n",
      "0.528518 (0.020126) with: {'model__optimizer__lr': 0.01}\n",
      "{'module': <class '__main__.NeuralNet'>, 'criterion': <class 'torch.nn.modules.loss.BCEWithLogitsLoss'>, 'optimizer': <class 'torch.optim.nadam.NAdam'>, 'lr': 5e-05, 'max_epochs': 1000, 'batch_size': 64, 'iterator_train': <class 'torch.utils.data.dataloader.DataLoader'>, 'iterator_valid': <class 'torch.utils.data.dataloader.DataLoader'>, 'dataset': <class 'skorch.dataset.Dataset'>, 'train_split': <skorch.dataset.ValidSplit object at 0x154a48af3250>, 'callbacks': [<skorch.callbacks.training.EarlyStopping object at 0x154b4c1977f0>], 'predict_nonlinearity': 'auto', 'warm_start': False, 'verbose': False, 'device': device(type='cpu'), '_params_to_validate': {'optimizer__lr'}, 'optimizer__lr': 0.001, 'threshold': 0.5, 'callbacks__epoch_timer': <skorch.callbacks.logging.EpochTimer object at 0x154a4899ac70>, 'callbacks__train_loss': <skorch.callbacks.scoring.PassthroughScoring object at 0x154a436336d0>, 'callbacks__train_loss__name': 'train_loss', 'callbacks__train_loss__lower_is_better': True, 'callbacks__train_loss__on_train': True, 'callbacks__valid_loss': <skorch.callbacks.scoring.PassthroughScoring object at 0x154a3af550a0>, 'callbacks__valid_loss__name': 'valid_loss', 'callbacks__valid_loss__lower_is_better': True, 'callbacks__valid_loss__on_train': False, 'callbacks__valid_acc': <skorch.callbacks.scoring.EpochScoring object at 0x154a3af55940>, 'callbacks__valid_acc__scoring': 'accuracy', 'callbacks__valid_acc__lower_is_better': False, 'callbacks__valid_acc__on_train': False, 'callbacks__valid_acc__name': 'valid_acc', 'callbacks__valid_acc__target_extractor': <function to_numpy at 0x154a4b3889d0>, 'callbacks__valid_acc__use_caching': True, 'callbacks__print_log': <skorch.callbacks.logging.PrintLog object at 0x154a3af55460>, 'callbacks__print_log__keys_ignored': None, 'callbacks__print_log__sink': <built-in function print>, 'callbacks__print_log__tablefmt': 'simple', 'callbacks__print_log__floatfmt': '.4f', 'callbacks__print_log__stralign': 'right'}\n",
      "Best: 0.544807 using {'model__module__n_neurons1': 16, 'model__module__n_neurons2': 16}\n",
      "0.523294 (0.027984) with: {'model__module__n_neurons1': 1, 'model__module__n_neurons2': 1}\n",
      "0.531856 (0.028731) with: {'model__module__n_neurons1': 1, 'model__module__n_neurons2': 2}\n",
      "0.537521 (0.026759) with: {'model__module__n_neurons1': 1, 'model__module__n_neurons2': 4}\n",
      "0.539091 (0.025981) with: {'model__module__n_neurons1': 1, 'model__module__n_neurons2': 8}\n",
      "0.537277 (0.025861) with: {'model__module__n_neurons1': 1, 'model__module__n_neurons2': 16}\n",
      "0.532283 (0.026214) with: {'model__module__n_neurons1': 1, 'model__module__n_neurons2': 32}\n",
      "0.526139 (0.029068) with: {'model__module__n_neurons1': 2, 'model__module__n_neurons2': 1}\n",
      "0.536020 (0.027442) with: {'model__module__n_neurons1': 2, 'model__module__n_neurons2': 2}\n",
      "0.540947 (0.025937) with: {'model__module__n_neurons1': 2, 'model__module__n_neurons2': 4}\n",
      "0.541648 (0.023927) with: {'model__module__n_neurons1': 2, 'model__module__n_neurons2': 8}\n",
      "0.540057 (0.024224) with: {'model__module__n_neurons1': 2, 'model__module__n_neurons2': 16}\n",
      "0.538602 (0.024371) with: {'model__module__n_neurons1': 2, 'model__module__n_neurons2': 32}\n",
      "0.527005 (0.028005) with: {'model__module__n_neurons1': 4, 'model__module__n_neurons2': 1}\n",
      "0.537023 (0.027176) with: {'model__module__n_neurons1': 4, 'model__module__n_neurons2': 2}\n",
      "0.542070 (0.023598) with: {'model__module__n_neurons1': 4, 'model__module__n_neurons2': 4}\n",
      "0.543677 (0.022475) with: {'model__module__n_neurons1': 4, 'model__module__n_neurons2': 8}\n",
      "0.541464 (0.024063) with: {'model__module__n_neurons1': 4, 'model__module__n_neurons2': 16}\n",
      "0.539927 (0.023774) with: {'model__module__n_neurons1': 4, 'model__module__n_neurons2': 32}\n",
      "0.530562 (0.028213) with: {'model__module__n_neurons1': 8, 'model__module__n_neurons2': 1}\n",
      "0.540118 (0.028082) with: {'model__module__n_neurons1': 8, 'model__module__n_neurons2': 2}\n",
      "0.543143 (0.024674) with: {'model__module__n_neurons1': 8, 'model__module__n_neurons2': 4}\n",
      "0.544177 (0.024623) with: {'model__module__n_neurons1': 8, 'model__module__n_neurons2': 8}\n",
      "0.543565 (0.025271) with: {'model__module__n_neurons1': 8, 'model__module__n_neurons2': 16}\n",
      "0.540987 (0.024397) with: {'model__module__n_neurons1': 8, 'model__module__n_neurons2': 32}\n",
      "0.528145 (0.027309) with: {'model__module__n_neurons1': 16, 'model__module__n_neurons2': 1}\n",
      "0.538905 (0.025659) with: {'model__module__n_neurons1': 16, 'model__module__n_neurons2': 2}\n",
      "0.542999 (0.024230) with: {'model__module__n_neurons1': 16, 'model__module__n_neurons2': 4}\n",
      "0.544005 (0.023983) with: {'model__module__n_neurons1': 16, 'model__module__n_neurons2': 8}\n",
      "0.544807 (0.024898) with: {'model__module__n_neurons1': 16, 'model__module__n_neurons2': 16}\n",
      "0.543509 (0.023534) with: {'model__module__n_neurons1': 16, 'model__module__n_neurons2': 32}\n",
      "0.527450 (0.027203) with: {'model__module__n_neurons1': 32, 'model__module__n_neurons2': 1}\n",
      "0.536793 (0.027833) with: {'model__module__n_neurons1': 32, 'model__module__n_neurons2': 2}\n",
      "0.543203 (0.025822) with: {'model__module__n_neurons1': 32, 'model__module__n_neurons2': 4}\n",
      "0.543606 (0.023343) with: {'model__module__n_neurons1': 32, 'model__module__n_neurons2': 8}\n",
      "0.544717 (0.023832) with: {'model__module__n_neurons1': 32, 'model__module__n_neurons2': 16}\n",
      "0.543902 (0.023886) with: {'model__module__n_neurons1': 32, 'model__module__n_neurons2': 32}\n",
      "{'module': <class '__main__.NeuralNet'>, 'criterion': <class 'torch.nn.modules.loss.BCEWithLogitsLoss'>, 'optimizer': <class 'torch.optim.nadam.NAdam'>, 'lr': 5e-05, 'max_epochs': 1000, 'batch_size': 64, 'iterator_train': <class 'torch.utils.data.dataloader.DataLoader'>, 'iterator_valid': <class 'torch.utils.data.dataloader.DataLoader'>, 'dataset': <class 'skorch.dataset.Dataset'>, 'train_split': <skorch.dataset.ValidSplit object at 0x154a48af3250>, 'callbacks': [<skorch.callbacks.training.EarlyStopping object at 0x154b4c1977f0>], 'predict_nonlinearity': 'auto', 'warm_start': False, 'verbose': False, 'device': device(type='cpu'), '_params_to_validate': {'optimizer__lr'}, 'optimizer__lr': 0.001, 'threshold': 0.5, 'n_neurons1': 16, 'n_neurons2': 16, 'callbacks__epoch_timer': <skorch.callbacks.logging.EpochTimer object at 0x154a4357f040>, 'callbacks__train_loss': <skorch.callbacks.scoring.PassthroughScoring object at 0x154a43633430>, 'callbacks__train_loss__name': 'train_loss', 'callbacks__train_loss__lower_is_better': True, 'callbacks__train_loss__on_train': True, 'callbacks__valid_loss': <skorch.callbacks.scoring.PassthroughScoring object at 0x154a4899ac70>, 'callbacks__valid_loss__name': 'valid_loss', 'callbacks__valid_loss__lower_is_better': True, 'callbacks__valid_loss__on_train': False, 'callbacks__valid_acc': <skorch.callbacks.scoring.EpochScoring object at 0x154a4357ba60>, 'callbacks__valid_acc__scoring': 'accuracy', 'callbacks__valid_acc__lower_is_better': False, 'callbacks__valid_acc__on_train': False, 'callbacks__valid_acc__name': 'valid_acc', 'callbacks__valid_acc__target_extractor': <function to_numpy at 0x154a4b3889d0>, 'callbacks__valid_acc__use_caching': True, 'callbacks__print_log': <skorch.callbacks.logging.PrintLog object at 0x154a3b8c3400>, 'callbacks__print_log__keys_ignored': None, 'callbacks__print_log__sink': <built-in function print>, 'callbacks__print_log__tablefmt': 'simple', 'callbacks__print_log__floatfmt': '.4f', 'callbacks__print_log__stralign': 'right'}\n",
      "Best: 0.544078 using {'model__module__dropout_prob': 0.2}\n",
      "0.544067 (0.024652) with: {'model__module__dropout_prob': 0.0}\n",
      "0.544078 (0.024679) with: {'model__module__dropout_prob': 0.2}\n",
      "0.543609 (0.024782) with: {'model__module__dropout_prob': 0.4}\n",
      "0.541140 (0.023708) with: {'model__module__dropout_prob': 0.6}\n",
      "0.522299 (0.023978) with: {'model__module__dropout_prob': 0.8}\n",
      "Final best parameters: {'model__optimizer': <class 'torch.optim.nadam.NAdam'>, 'model__optimizer__lr': 5e-05, 'model__module__n_neurons1': 16, 'model__module__n_neurons2': 16, 'model__module__dropout_prob': 0.2}\n"
     ]
    }
   ],
   "source": [
    "# Iterate through param_grids\n",
    "for param_grid in param_grids:\n",
    "    steps = [\n",
    "        (\"scale\", preprocessor),\n",
    "        # ('smoteenn', smoteenn),\n",
    "        # ('over', over),\n",
    "        (\"smote\", smote),\n",
    "        # ('tofloat32_', FunctionTransformer(tofloat32, accept_sparse=True)),\n",
    "        (\"under\", under),\n",
    "        (\"tofloat32\", FunctionTransformer(tofloat32, accept_sparse=True)),\n",
    "        (\"model\", model),\n",
    "    ]\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "\n",
    "    print(model.get_params())\n",
    "    \n",
    "    grid = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid=param_grid,\n",
    "        #search_optimization='hyperopt',\n",
    "        #random_state=42,\n",
    "        scoring=roc_auc_score_2,\n",
    "        n_jobs=-1,\n",
    "        cv=cv,\n",
    "        verbose=0,\n",
    "        #use_gpu=True,\n",
    "    )    \n",
    "\n",
    "    grid_result = grid.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "    # Update the model with the best parameters\n",
    "    for key, value in grid_result.best_params_.items():\n",
    "        setattr(model, key.split(\"__\")[-1], value)\n",
    "\n",
    "    # Print the best parameters and score\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    means = grid_result.cv_results_[\"mean_test_score\"]\n",
    "    stds = grid_result.cv_results_[\"std_test_score\"]\n",
    "    params = grid_result.cv_results_[\"params\"]\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "    # Update the best_params dictionary\n",
    "    best_params.update(grid_result.best_params_)\n",
    "\n",
    "# Print the final best_params dictionary\n",
    "print(\"Final best parameters:\", best_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scale',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('scaler', StandardScaler(),\n",
       "                                                  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                                                   10, 11, 12, 13, 14, 15, 16,\n",
       "                                                   17, 18, 20, 21, 22, 23, 24,\n",
       "                                                   26, 27, 28, 46, 47, 48])])),\n",
       "                ('smote', SMOTE(random_state=42, sampling_strategy=0.5)),\n",
       "                ('under',\n",
       "                 RandomUnderSampler(random_state=42, sampling_strategy=1)),\n",
       "                ('tofloat32',\n",
       "                 FunctionTransformer(ac...\n",
       "                                     func=<function tofloat32 at 0x154a43380550>)),\n",
       "                ('model',\n",
       "                 <class 'skorch.classifier.NeuralNetBinaryClassifier'>[initialized](\n",
       "  module_=NeuralNet(\n",
       "    (layer1): Linear(in_features=57, out_features=8, bias=True)\n",
       "    (dropout1): Dropout(p=0.2, inplace=False)\n",
       "    (layer2): Linear(in_features=8, out_features=8, bias=True)\n",
       "    (dropout2): Dropout(p=0.2, inplace=False)\n",
       "    (layer3): Linear(in_features=8, out_features=1, bias=True)\n",
       "  ),\n",
       "))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_estimator_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hda]",
   "language": "python",
   "name": "conda-env-hda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
